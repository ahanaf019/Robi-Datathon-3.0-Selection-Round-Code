{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Glorious Imports for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter\n",
    "\n",
    "# Our Glorious Imports for Models \n",
    "\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Robi Datathon 3.0 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_df = pd.read_csv(\"./dataset/purchase.csv\")  # Train SET\n",
    "problem_df = pd.read_csv(\"./dataset/problem 2.csv\")  # Test SET\n",
    "\n",
    "# get the total unique MAGIC_KEYS in file\n",
    "train_keys = np.unique(purchase_df[\"MAGIC_KEY\"].to_list())\n",
    "test_keys = np.unique(problem_df[\"MAGIC_KEY\"].to_list())\n",
    "\n",
    "# Debugging\n",
    "print(f'Unique keys in train set: {len(train_keys)}')\n",
    "print(f'Unique keys in test set: {len(test_keys)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the Magic Key is in out test set\n",
    "temp_df = purchase_df[purchase_df['MAGIC_KEY'].isin(test_keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning \n",
    "purchase_df = purchase_df[purchase_df['BOX_COUNT'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse  datetime column and set it as index\n",
    "def parse_datetime(df):\n",
    "    df['PURCHASE_DATE'] = pd.to_datetime(df['PURCHASE_DATE'], format=\"%d/%m/%Y\")\n",
    "    df.set_index('PURCHASE_DATE', inplace=True)\n",
    "    return df\n",
    "\n",
    "temp_df = parse_datetime(temp_df)\n",
    "purchase_df = parse_datetime(purchase_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Groups of timescale dataset\n",
    "def slice_dataframe_by_dates(df):\n",
    "    days_groups = []\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2018-10-01' and PURCHASE_DATE <= '2018-10-15'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2018-10-16' and PURCHASE_DATE <= '2018-10-31'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2018-11-01' and PURCHASE_DATE <= '2018-11-15'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2018-11-16' and PURCHASE_DATE <= '2018-11-30'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2018-12-01' and PURCHASE_DATE <= '2018-12-15'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2018-12-16' and PURCHASE_DATE <= '2018-12-31'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2019-01-01' and PURCHASE_DATE <= '2019-01-15'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2019-01-16' and PURCHASE_DATE <= '2019-01-31'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2019-02-01' and PURCHASE_DATE <= '2019-02-15'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2019-02-16' and PURCHASE_DATE <= '2019-02-28'\") )\n",
    "    return days_groups\n",
    "\n",
    "# get smaller slices of my groups\n",
    "test_purchase_groups = slice_dataframe_by_dates(temp_df)\n",
    "all_purchase_groups = slice_dataframe_by_dates(purchase_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset from groups based on unique keys\n",
    "def create_dataset_from_groups(unique_keys_list, days_groups):\n",
    "    # Initialize an empty DataFrame\n",
    "    new_dataset = pd.DataFrame()\n",
    "    new_dataset['MAGIC_KEY'] = unique_keys_list\n",
    "\n",
    "    # Iterate over each days group\n",
    "    for days_groupname, days_group_data in enumerate(days_groups):\n",
    "        # Check if the MAGIC_KEY is present in the days_group_data and convert to uint8\n",
    "        new_dataset[f'col_{days_groupname}'] = new_dataset['MAGIC_KEY'].isin(days_group_data['MAGIC_KEY']).astype(np.uint8)\n",
    "        \n",
    "        # Initialize lists to store box counts and box IDs\n",
    "        _box_counts = []\n",
    "        _box_ids = []\n",
    "        \n",
    "        # Iterate over each row in the new dataset\n",
    "        for idx, data in enumerate(new_dataset[f'col_{days_groupname}']):\n",
    "            if data == 0:\n",
    "                # If the MAGIC_KEY is not in the group, set box counts and IDs to 0\n",
    "                _box_counts.append([0])\n",
    "                _box_ids.append([0])\n",
    "            else:\n",
    "                # Otherwise, retrieve box counts and IDs from the days_group_data\n",
    "                g = days_group_data[days_group_data['MAGIC_KEY'] == new_dataset.iloc[idx, 0]]\n",
    "                _box_counts.append(g['BOX_COUNT'].to_list())\n",
    "                _box_ids.append(g['BOX_ID'].to_list())\n",
    "        \n",
    "        # Add box counts and box IDs columns to the new dataset\n",
    "        new_dataset[f'col_{days_groupname}_box_counts'] = _box_counts\n",
    "        new_dataset[f'col_{days_groupname}_box_ids'] = _box_ids\n",
    "    \n",
    "    return new_dataset\n",
    "\n",
    "# Assuming test_purchase_groups, temp_df, test_keys, and all_purchase_groups are defined elsewhere\n",
    "days_groups = test_purchase_groups\n",
    "dataset = temp_df\n",
    "\n",
    "# Create test and train datasets\n",
    "test_df = create_dataset_from_groups(test_keys, test_purchase_groups)\n",
    "train_df = create_dataset_from_groups(train_keys, all_purchase_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_in_both(list1, list2):\n",
    "    # Count occurrences of each element in list1\n",
    "    count1 = Counter(list1)\n",
    "    # Filter the Counter to include only elements present in list2\n",
    "    filtered_count = {k: v for k, v in count1.items() if k in list2}\n",
    "    \n",
    "    if not filtered_count:\n",
    "        return None  # No common elements found\n",
    "    \n",
    "    # Get the most common element among the filtered elements\n",
    "    most_common_element = max(filtered_count, key=filtered_count.get)\n",
    "    return most_common_element\n",
    "\n",
    "\n",
    "def process(row):\n",
    "    choices = []\n",
    "    for i in range(1, row.shape[0]):\n",
    "        if 0 in row.iloc[i]:\n",
    "            row.iloc[i] = 0\n",
    "        else:\n",
    "            if len(row.iloc[i]) == 1:\n",
    "                row.iloc[i] = row.iloc[i][0]\n",
    "                choices.append(row.iloc[i])\n",
    "            else:\n",
    "                choices += row.iloc[i]\n",
    "                # row.iloc[i] = most_common_in_both(choices, row.iloc[i])\n",
    "    for i in range(1, row.shape[0]):\n",
    "        if type(row.iloc[i]) == list:\n",
    "            row.iloc[i] = most_common_in_both(choices, row.iloc[i])\n",
    "    # print(row)\n",
    "    return row\n",
    "\n",
    "\n",
    "# Renaming for our convenience \n",
    "def process_dataset(df):\n",
    "    df = df.drop(['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8', 'col_9', 'col_0_box_counts', 'col_1_box_counts', 'col_2_box_counts', 'col_3_box_counts', 'col_4_box_counts', 'col_5_box_counts', 'col_6_box_counts', 'col_7_box_counts', 'col_8_box_counts', 'col_9_box_counts'], axis=1)\n",
    "    df = df.apply(process, axis=1)\n",
    "    \n",
    "    col_name_maps = {\n",
    "        'col_0_box_ids': '1st',\n",
    "        'col_1_box_ids': '2nd',\n",
    "        'col_2_box_ids': '3rd',\n",
    "        'col_3_box_ids': '4th',\n",
    "        'col_4_box_ids': '5th',\n",
    "        'col_5_box_ids': '6th',\n",
    "        'col_6_box_ids': '7th',\n",
    "        'col_7_box_ids': '8th',\n",
    "        'col_8_box_ids': '9th',\n",
    "        'col_9_box_ids': '10th',}\n",
    "    df = df.rename(col_name_maps, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "test_df = process_dataset(test_df)\n",
    "train_df = process_dataset(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataset\n",
    "test_df.to_csv('data/problem-2-test.csv', index=False)\n",
    "train_df.to_csv('data/problem-2-train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Preprocessed dataset and Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Datasets\n",
    "problem_df = pd.read_csv('dataset/problem 2.csv')\n",
    "train_dataset = pd.read_csv('data/problem-2-train.csv')\n",
    "test_dataset = pd.read_csv('data/problem-2-test.csv')\n",
    "problem_df = test_dataset['MAGIC_KEY']\n",
    "\n",
    "train_dataset.shape, test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'MAGIC_KEY'\n",
    "train_dataset.drop('MAGIC_KEY', axis=1, inplace=True)\n",
    "test_dataset.drop('MAGIC_KEY', axis=1, inplace=True)\n",
    "\n",
    "train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter last column's zero values as customers must buy something\n",
    "train_dataset = train_dataset[train_dataset['10th'] != 0.0]\n",
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter all zero rows \n",
    "train_dataset = train_dataset[\n",
    "    (train_dataset['1st'] != 0.0) |\n",
    "    (train_dataset['2nd'] != 0.0) |\n",
    "    (train_dataset['3rd'] != 0.0) |\n",
    "    (train_dataset['4th'] != 0.0) |\n",
    "    (train_dataset['5th'] != 0.0) |\n",
    "    (train_dataset['6th'] != 0.0) |\n",
    "    (train_dataset['7th'] != 0.0) |\n",
    "    (train_dataset['8th'] != 0.0) |\n",
    "    (train_dataset['9th'] != 0.0)]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Global One Hot Encoder\n",
    "encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "def one_hot_encoder(df, column):\n",
    "    encoded_data = encoder.fit_transform(df[[column]])\n",
    "    encoded_df = pd.DataFrame(encoded_data.toarray(), columns=encoder.get_feature_names_out([column]))\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Decoding\n",
    "def one_hot_decoder(df, column):\n",
    "    decoded_values = encoder.inverse_transform(df)\n",
    "    decoded_df = pd.DataFrame(decoded_values, columns=[column])\n",
    "    return decoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train dataset\n",
    "def create_dataset(df, is_test = False):\n",
    "    keys = ['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th']\n",
    "    train_x = pd.DataFrame()\n",
    "    train_y = pd.DataFrame()\n",
    "\n",
    "    for key in keys:\n",
    "        encoded_df = one_hot_encoder(df, key)\n",
    "        train_x = pd.concat([train_x, encoded_df], axis=1)\n",
    "    \n",
    "    if not is_test:\n",
    "        # train_y = one_hot_encoder(df, '10th')  # Not Use One Hot Encoding\n",
    "        train_y = df['10th'].astype(int)\n",
    "    \n",
    "    return (train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting and Formatting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset splitting function\n",
    "def get_x_y_dataset(df, is_final_train=False, is_test=False, test_size=None):\n",
    "    # Create features (X) and labels (Y) from the input DataFrame\n",
    "    X, Y = create_dataset(df, is_test)\n",
    "    \n",
    "    if is_final_train:\n",
    "        # return the entire dataset\n",
    "        return (X, Y)\n",
    "    \n",
    "    # split the dataset into train and test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)\n",
    "    \n",
    "    return (x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily split the train set for understanding model performance\n",
    "x_train, x_test, y_train, y_test = get_x_y_dataset(train_dataset.sample(2000), False, False, 0.2)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models with parameters for checking the best fit model \n",
    "\n",
    "model_params = {\n",
    "    'svm':{\n",
    "        'model': SVC(gamma='auto'),\n",
    "        'params': {\n",
    "            'C': [1, 3, 5, 10, 20, 30, 50, 100, 500],\n",
    "            'kernel': ['rbf']\n",
    "        }\n",
    "    },\n",
    "    'random_forest':{\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [1, 5, 10, 18, 20, 30],\n",
    "            'n_jobs': [-1],\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression':{\n",
    "        'model': LogisticRegression(solver='liblinear', multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1,5,10],\n",
    "            'max_iter': [1000],\n",
    "        }\n",
    "    },\n",
    "    'decision_tree':{\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "        }\n",
    "    },\n",
    "    'multinomial_nb':{\n",
    "        'model': MultinomialNB(), \n",
    "        'params': {\n",
    "            \n",
    "        }\n",
    "    },\n",
    "    'gaussian_nb':{\n",
    "        'model': GaussianNB(), \n",
    "        'params': {\n",
    "            \n",
    "        }\n",
    "    },\n",
    "    'gradient-boosting':{\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'loss': ['log_loss'],\n",
    "            'learning_rate': [0.1, 0.01, 0.001]\n",
    "        }\n",
    "    },\n",
    "    'hist-gradient-boosting':{\n",
    "        'model': HistGradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'learning_rate': [0.1, 0.01, 0.001],\n",
    "            'max_iter': [1000, 500]\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store model scores without one hot\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False, verbose = 3)\n",
    "    clf.fit(x_train, y_train)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best results of the models\n",
    "df_res = pd.DataFrame(scores,columns=['model', 'best_score', 'best_params'])\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameter Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models with parameters for checking the best fit model \n",
    "\n",
    "model_params = {\n",
    "    'logistic_regression':{\n",
    "        'model': LogisticRegression(solver='liblinear', multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1,5,10],\n",
    "            'max_iter': [1000],\n",
    "        }\n",
    "    },\n",
    "    'multinomial_nb':{\n",
    "        'model': MultinomialNB(), \n",
    "        'params': {\n",
    "            \n",
    "        }\n",
    "    },\n",
    "    'gradient-boosting':{\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'loss': ['log_loss', 'exponential'],\n",
    "            'learning_rate': [0.1, 0.01, 0.001]\n",
    "        }\n",
    "    },\n",
    "    'hist-gradient-boosting':{\n",
    "        'model': HistGradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'learning_rate': [0.1, 0.01, 0.001],\n",
    "            'max_iter': [1000, 500]\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store model scores with one hot\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(x_train, y_train)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual checking model performence \n",
    "def fit_and_evaluate(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train, )\n",
    "    result = model.score(x_test, y_test)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling algorithm for best match\n",
    "def rolling_algorithm(df):\n",
    "    df['1st'] = df['2nd']\n",
    "    df['2nd'] = df['3rd']\n",
    "    df['3rd'] = df['4th']\n",
    "    df['4th'] = df['5th']\n",
    "    df['5th'] = df['6th']\n",
    "    df['6th'] = df['7th']\n",
    "    df['7th'] = df['8th']\n",
    "    df['8th'] = df['9th']\n",
    "    df['9th'] = df['10th']\n",
    "    df = df.drop('10th', axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the predicted result in a CSV\n",
    "def save_results(magic_keys, predicts, file_name):\n",
    "    result = pd.DataFrame()\n",
    "    # result = one_hot_decoder(predicts, 'BOX_ID')\n",
    "    result['BOX_ID'] = predicts\n",
    "    \n",
    "    final_df = pd.concat([magic_keys, result], axis=1, )\n",
    "    final_df['BOX_ID'] = final_df['BOX_ID'].astype(int)\n",
    "    final_df.to_csv(f\"./solution/{file_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model, predict on the test set and store \n",
    "def fit_predict_and_save(model, x_train, y_train, x_test, magic_keys, file_name):\n",
    "    model.fit(x_train, y_train)\n",
    "    predicts = model.predict(x_test)\n",
    "    pickle.dump(model, open(f\"./model/{file_name}.pkl\", 'wb'))\n",
    "    save_results(magic_keys, predicts, file_name)\n",
    "    print(f'File: {file_name} Stored Successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual train-test splitting for final training and test data\n",
    "\n",
    "#  Get features (X) and labels (Y) for final training\n",
    "X, Y = get_x_y_dataset(train_dataset, True)\n",
    "\n",
    "#Apply the rolling_algorithm to modify the test dataset\n",
    "test_dataset = rolling_algorithm(test_dataset)\n",
    "\n",
    "# Create a dataset from the modified test data\n",
    "test_dataset, _ = create_dataset(test_dataset, True)\n",
    "\n",
    "#  Identify common columns between X and the modified test dataset\n",
    "common_columns = X.columns.intersection(test_dataset.columns)\n",
    "\n",
    "#  Update X to include only the common columns\n",
    "X = X[common_columns]\n",
    "\n",
    "# Keep the modified test dataset unchanged\n",
    "test_dataset = test_dataset\n",
    "\n",
    "\n",
    "X.shape, Y.shape, test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on final model\n",
    "model = RandomForestClassifier(n_estimators=18, n_jobs=-1)\n",
    "fit_predict_and_save(model, X, Y, test_dataset, problem_df, \"submission_random_forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on final model\n",
    "model = SVC(C=2, kernel='rbf', verbose = True)\n",
    "fit_predict_and_save(model, X, Y, test_dataset, problem_df, \"submission_svc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.15",
   "language": "python",
   "name": "tf2.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
