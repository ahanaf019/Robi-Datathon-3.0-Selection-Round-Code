{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Env-Variables and Enable Mixed-Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' \n",
    "\n",
    "# https://github.com/tensorflow/tensorflow/issues/53519\n",
    "os.environ['TF_DEVICE_MIN_SYS_MEMORY_IN_MB'] = '256' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import keras\n",
    "import  tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Dataset for Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = pd.read_csv('./datasets/boxes.csv')\n",
    "purchase_df = pd.read_csv(\"./datasets/purchase.csv\")  # Train SET\n",
    "problem_df = pd.read_csv(\"./datasets/problem 3.csv\")  # Test SET\n",
    "\n",
    "# get the total unique MAGIC_KEYS in file\n",
    "train_keys = np.unique(purchase_df[\"MAGIC_KEY\"].to_list())\n",
    "test_keys = np.unique(problem_df[\"MAGIC_KEY\"].to_list())\n",
    "\n",
    "\n",
    "# Debugging\n",
    "print(f'Unique keys in train set: {len(train_keys)}')\n",
    "print(f'Unique keys in test set: {len(test_keys)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the Magic Key is in out test set\n",
    "temp_df = purchase_df[purchase_df['MAGIC_KEY'].isin(test_keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning \n",
    "purchase_df = purchase_df[purchase_df['BOX_COUNT'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse  datetime column and set it as index\n",
    "def parse_datetime(df):\n",
    "    df['PURCHASE_DATE'] = pd.to_datetime(df['PURCHASE_DATE'], format=\"%d/%m/%Y\")\n",
    "    df.set_index('PURCHASE_DATE', inplace=True)\n",
    "    return df\n",
    "# more housekeeping\n",
    "temp_df = parse_datetime(temp_df)\n",
    "purchase_df = parse_datetime(purchase_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Groups of timescale dataset\n",
    "def slice_dataframe_by_dates(df):\n",
    "    days_groups = []\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2018-10-01' and PURCHASE_DATE <= '2018-10-15'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2018-10-16' and PURCHASE_DATE <= '2018-10-31'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2018-11-01' and PURCHASE_DATE <= '2018-11-15'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2018-11-16' and PURCHASE_DATE <= '2018-11-30'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2018-12-01' and PURCHASE_DATE <= '2018-12-15'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2018-12-16' and PURCHASE_DATE <= '2018-12-31'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2019-01-01' and PURCHASE_DATE <= '2019-01-15'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2019-01-16' and PURCHASE_DATE <= '2019-01-31'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2019-02-01' and PURCHASE_DATE <= '2019-02-15'\") )\n",
    "    days_groups.append( df.query(\"PURCHASE_DATE >= '2019-02-16' and PURCHASE_DATE <= '2019-02-28'\") )\n",
    "    return days_groups\n",
    "\n",
    "# get smaller slices of my groups\n",
    "test_purchase_groups = slice_dataframe_by_dates(temp_df)\n",
    "all_purchase_groups = slice_dataframe_by_dates(purchase_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset from groups based on unique keys\n",
    "def create_dataset_from_groups(unique_keys_list, days_groups):\n",
    "    # Initialize an empty DataFrame\n",
    "    new_dataset = pd.DataFrame()\n",
    "    new_dataset['MAGIC_KEY'] = unique_keys_list\n",
    "\n",
    "    # Iterate over each days group\n",
    "    for days_groupname, days_group_data in enumerate(days_groups):\n",
    "        # Check if the MAGIC_KEY is present in the days_group_data and convert to uint8\n",
    "        new_dataset[f'col_{days_groupname}'] = new_dataset['MAGIC_KEY'].isin(days_group_data['MAGIC_KEY']).astype(np.uint8)\n",
    "        \n",
    "        # Initialize lists to store box counts and box IDs\n",
    "        _box_counts = []\n",
    "        _box_ids = []\n",
    "        _box_meats = []\n",
    "        \n",
    "        # Iterate over each row in the new dataset\n",
    "        for idx, data in enumerate(new_dataset[f'col_{days_groupname}']):\n",
    "            if data == 0:\n",
    "                # If the MAGIC_KEY is not in the group, set box counts, milks and meats and IDs to 0\n",
    "                _box_counts.append(0)\n",
    "                _box_ids.append(0)\n",
    "                _box_meats.append(0)\n",
    "            else:\n",
    "                meats = 0\n",
    "                \n",
    "                # Otherwise, retrieve amount of milk and meat from the days_group_data\n",
    "                g = days_group_data[days_group_data['MAGIC_KEY'] == new_dataset.iloc[idx, 0]]\n",
    "                _box_counts.append(g['BOX_COUNT'].to_list())\n",
    "                _box_ids.append(g['BOX_ID'].to_list())\n",
    "                for x in range(len(_box_counts[-1])):\n",
    "                    meats += _box_counts[-1][x] * boxes.iloc[int(_box_ids[-1][x])-1, 4]\n",
    "                _box_meats.append(meats)\n",
    "        \n",
    "        # Add box meat volume column to the new dataset\n",
    "        new_dataset[f'col_{days_groupname}_meat'] = _box_meats\n",
    "        # new_dataset[f'col_{days_groupname}_box_counts'] = _box_counts\n",
    "        # new_dataset[f'col_{days_groupname}_box_ids'] = _box_ids\n",
    "    \n",
    "    return new_dataset\n",
    "\n",
    "# Assuming test_purchase_groups, temp_df, test_keys, and all_purchase_groups are defined elsewhere\n",
    "days_groups = test_purchase_groups\n",
    "dataset = temp_df\n",
    "\n",
    "# Create test and train datasets\n",
    "test_df = create_dataset_from_groups(test_keys, test_purchase_groups)\n",
    "train_df = create_dataset_from_groups(train_keys, all_purchase_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming for our convenience \n",
    "def process_dataset(df):\n",
    "    df = df.drop(['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8', 'col_9'], axis=1)\n",
    "    \n",
    "    col_name_maps = {\n",
    "        'col_0_meat': '1st',\n",
    "        'col_1_meat': '2nd',\n",
    "        'col_2_meat': '3rd',\n",
    "        'col_3_meat': '4th',\n",
    "        'col_4_meat': '5th',\n",
    "        'col_5_meat': '6th',\n",
    "        'col_6_meat': '7th',\n",
    "        'col_7_meat': '8th',\n",
    "        'col_8_meat': '9th',\n",
    "        'col_9_meat': '10th',}\n",
    "    df = df.rename(col_name_maps, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "test_df = process_dataset(test_df)\n",
    "train_df = process_dataset(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataset\n",
    "test_df.to_csv('data/problem-3-test.csv', index=False)\n",
    "train_df.to_csv('data/problem-3-train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Preprocessed dataset and Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_phase1 = pd.read_csv(\"./data/problem-3-train.csv\")\n",
    "df_phase2 = pd.read_csv(\"./data/problem-3-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAGIC_KEY</th>\n",
       "      <th>1st</th>\n",
       "      <th>2nd</th>\n",
       "      <th>3rd</th>\n",
       "      <th>4th</th>\n",
       "      <th>5th</th>\n",
       "      <th>6th</th>\n",
       "      <th>7th</th>\n",
       "      <th>8th</th>\n",
       "      <th>9th</th>\n",
       "      <th>10th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249670911D8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249751FC4DD</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24978027606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24979164422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2497B8B4FDA</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>24AB707A0D3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>24AB77B25A6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>24AB7C0779C</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>24AB85041D3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>24ABD4FE7F6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MAGIC_KEY  1st  2nd  3rd  4th  5th  6th  7th  8th  9th  10th\n",
       "0   249670911D8  0.0  0.0  2.4  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "1   249751FC4DD  1.8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "2   24978027606  0.0  2.9  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "3   24979164422  0.0  0.0  0.0  2.5  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "4   2497B8B4FDA  1.8  0.0  3.6  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "..          ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...\n",
       "95  24AB707A0D3  0.0  2.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "96  24AB77B25A6  0.0  0.0  2.2  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "97  24AB7C0779C  3.3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "98  24AB85041D3  1.8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "99  24ABD4FE7F6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phase1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(checkpoint_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(8, 1))) \n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(LSTM(units=64))\n",
    "\n",
    "    # Add the output layer\n",
    "    model.add(Dense(1,   activation='linear', dtype=tf.float32))\n",
    "    \n",
    "    if checkpoint_path is not None:\n",
    "        print('Loading Weights')\n",
    "        model.load_weights(checkpoint_path)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def compile_and_fit_model(model, train_data, learning_rate, save_path='model_2.keras'):\n",
    "    trainX, trainY = train_data\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=learning_rate), metrics=[keras.metrics.R2Score()])\n",
    "    history = model.fit(\n",
    "        trainX, trainY, \n",
    "        epochs=1000, \n",
    "        batch_size=4096*2, \n",
    "        validation_split=0.1, \n",
    "        callbacks=[\n",
    "            keras.callbacks.ModelCheckpoint(save_path, save_best_only=True, save_weights_only=False, verbose=1),\n",
    "            keras.callbacks.ReduceLROnPlateau(patience=20, factor=0.1),\n",
    "            keras.callbacks.EarlyStopping(patience=50)\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_phase1.iloc[:, 1:17].to_numpy().astype(np.float32)\n",
    "Y = df_phase1.iloc[:, 17].to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_phase(df, pretrained_checkpoint=None, save_path=None):\n",
    "    X = df.iloc[:, 1:17].to_numpy().astype(np.float32)\n",
    "    Y = df.iloc[:, 17].to_numpy().astype(np.float32)\n",
    "    \n",
    "    trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    trainX = np.expand_dims(trainX, axis=-1)\n",
    "    testX = np.expand_dims(testX, axis=-1)\n",
    "    \n",
    "    model = get_model(checkpoint_path=pretrained_checkpoint)\n",
    "    compile_and_fit_model(model, (trainX, trainY), 1e-3, save_path=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially train with the training dataset\n",
    "train_phase(df_phase1, None, save_path='model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In phase 2, fine-tune the model\n",
    "train_phase(df_phase2, 'model.keras', 'model_finetune.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3rd</th>\n",
       "      <th>4th</th>\n",
       "      <th>5th</th>\n",
       "      <th>6th</th>\n",
       "      <th>7th</th>\n",
       "      <th>8th</th>\n",
       "      <th>9th</th>\n",
       "      <th>10th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    3rd  4th  5th  6th  7th  8th  9th  10th\n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "3   2.2  0.0  0.0  2.2  0.0  0.0  0.0   0.0\n",
       "4   0.0  2.2  0.0  0.0  0.0  0.0  2.2   0.0\n",
       "..  ...  ...  ...  ...  ...  ...  ...   ...\n",
       "95  0.0  0.0  0.0  0.0  0.0  0.0  2.5   0.0\n",
       "96  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "97  0.0  0.0  0.0  0.0  0.0  0.0  0.0   1.8\n",
       "98  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "99  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phase2.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict from model and create a submission\n",
    "def create_submission(checkpoint_path, out_csv_filename='submission.csv'):\n",
    "    # Load pretrained weights after training and fine-tuning is done\n",
    "    model = get_model(checkpoint_path)\n",
    "    X = df_phase2.iloc[:, 3:]\n",
    "    preds = model.predict(X)\n",
    "    preds = preds.reshape(-1,)\n",
    "    submission = pd.DataFrame()\n",
    "    submission['MEAT'] = preds\n",
    "    submission[\"MAGIC_KEY\"] = df_phase2['MAGIC_KEY']\n",
    "    submission.to_csv(out_csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission('model_finetune.keras', 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.15",
   "language": "python",
   "name": "tf2.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
